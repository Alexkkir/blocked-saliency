{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 17:57:29.567127: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alexkkir/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-05-08 17:57:29.567273: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Kuti\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from math import ceil\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import random\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['animation.ffmpeg_path_vid_vid_vid_vid'] = r'C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe'\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from koniq_api.lib import MyModel\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model InceptionResNetV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 17:57:32.511882: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-08 17:57:32.512005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (alexkkir-Extensa-215-51G): /proc/driver/nvidia/version does not exist\n",
      "2022-05-08 17:57:32.513449: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "MODEL = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VideoReader:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        if not os.path.exists(path):\n",
    "            print(f'Path {path} doesnt exists')\n",
    "        else:\n",
    "            print('Path exists')\n",
    "        self.cap = cv2.VideoCapture(path)\n",
    "        self.height = int(self.cap.get(4))\n",
    "        self.width = int(self.cap.get(3))\n",
    "        self.it = iter(self)\n",
    "        self.length = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    def __iter__(self):\n",
    "        while self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            yield frame\n",
    "\n",
    "    def __call__(self):\n",
    "        return next(self.it)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.cap.release()\n",
    "\n",
    "    def refresh(self):\n",
    "        self.cap = cv2.VideoCapture(self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 2\n",
    "\n",
    "class MetricArray:\n",
    "    def __init__(self, vid_path, mask_path, n_height, n_width):\n",
    "        self.vid = None if vid_path is None else VideoReader(vid_path)\n",
    "        self.mask_raw = None if mask_path is None else VideoReader(mask_path)\n",
    "        \n",
    "        self.n_height = n_height\n",
    "        self.n_width = n_width\n",
    "        self.block_height = self.vid.height // n_height\n",
    "        self.block_width = self.vid.width // n_width\n",
    "        \n",
    "        self.scores = np.zeros((self.vid.length, self.n_height, self.n_width))\n",
    "        self.metric = MODEL\n",
    "        self.mask = np.zeros_like(self.scores)\n",
    "        self.length = self.vid.length\n",
    "\n",
    "    def get_subframe(self, frame, i, j) -> np.array:\n",
    "        return frame[\n",
    "               i * self.block_height: min(self.vid.height, (i + 1) * self.block_height),\n",
    "               j * self.block_width: min(self.vid.width, (j + 1) * self.block_width)\n",
    "               ]\n",
    "\n",
    "    def split_video(self):\n",
    "        \"\"\"\n",
    "        devide video on n * m subvideos and save each of them in ./tmp/ folder\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        TMP_DIR = './tmp/'\n",
    "        if not os.path.exists(TMP_DIR): \n",
    "            os.mkdir(TMP_DIR)\n",
    "        for f in os.listdir(TMP_DIR):\n",
    "            os.remove(TMP_DIR + f)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "        for i in range(self.n_height):\n",
    "            for j in range(self.n_width):\n",
    "                out = cv2.VideoWriter(f'{TMP_DIR}{i}_{j}.mp4', fourcc, vid.fps, (self.block_width, self.block_height))\n",
    "                for frame in vid:\n",
    "                    subframe = self.get_subframe(frame, i, j)\n",
    "                    out.write(subframe)\n",
    "                out.release()\n",
    "                vid.refresh()\n",
    "                \n",
    "    \n",
    "    def calc_raw_metric(self):\n",
    "        for frame_idx, frame in tqdm(enumerate(self.vid), total=self.length):\n",
    "            for i in range(self.n_height):\n",
    "                for j in range(self.n_width):\n",
    "                    subframe = self.get_subframe(frame, i, j)\n",
    "                    score = self.metric(subframe)\n",
    "                    self.scores[frame_idx][i][j] = score\n",
    "    \n",
    "    def resize_mask(self):\n",
    "        self.mask_raw.refresh()\n",
    "        for fi, frame in enumerate(self.mask_raw):\n",
    "            frame = cv2.resize(frame, (self.vid.width, self.vid.height)).astype('uint8')\n",
    "            for i in range(self.mask.shape[1]):\n",
    "                for j in range(self.mask.shape[2]):\n",
    "                    self.mask[fi][i][j] = frame[ \n",
    "                        i * self.block_height : (i + 1) * (self.block_height ), \n",
    "                        j * self.block_width: (j + 1) * (self.block_width)].mean() / 255     \n",
    "        self.mask_raw.refresh()\n",
    "\n",
    "\n",
    "    def apply_mask(self):\n",
    "        return self.scores * self.mask\n",
    "    \n",
    "    def calc_metric(self):\n",
    "        return self.apply_mask().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pcc(x, y):\n",
    "    return np.corrcoef(x, y)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(name: str) -> dict[str]:\n",
    "    out = dict()\n",
    "    name = name.split('.')[0]\n",
    "    name = name.split('enc_res_')[1]\n",
    "\n",
    "    str1 = '_mv_offline_2k_v1_'\n",
    "    str2 = '_mv_offline_2k_'\n",
    "\n",
    "    if name.find(str1) >= 0:\n",
    "        method = 'mv_offline_2k_v1'\n",
    "        name = name.split(str1)\n",
    "    else:\n",
    "        method = 'mv_offline_2k'\n",
    "        name = name.split(str2)\n",
    "\n",
    "    out['method'] = method\n",
    "    out['codec'] = name[0]\n",
    "\n",
    "    name = name[1]\n",
    "    name = name.split('_')\n",
    "    out['crf'] = int(name[-1])\n",
    "\n",
    "    name = '_'.join(name[0:-1])\n",
    "    out['name'] = name\n",
    "    return out\n",
    "\n",
    "def get_1_score(df: pd.DataFrame, name, codec, crf, method):\n",
    "    x = df[(df['comparison'] == 'ugc') & (df['sequence'] == name) & (df['crf'] == int(crf)) & (df['codec'] == codec) & (\n",
    "            df['preset'] == method)]\n",
    "    x = x['subjective']\n",
    "\n",
    "    if len(x) == 1:\n",
    "        x = float(x)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_subj_scores(videos, file='subjective_scores.csv'):\n",
    "    subj = pd.read_csv(file, sep=';')\n",
    "    return [get_1_score(subj, **parse(name)) for name in videos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metric_single(ma: MetricArray, subjs: list, metric, param, give_scores):\n",
    "    scores = []\n",
    "    for video, bscore in zip(videos, bscores):\n",
    "        ma.scores = bscore\n",
    "        if param is None:\n",
    "            score = metric(ma)\n",
    "        else:\n",
    "            score = metric(ma, **param)\n",
    "        scores.append(score)\n",
    "    if give_scores:\n",
    "        return calc_pcc(scores, subjs), scores\n",
    "    else:\n",
    "        return calc_pcc(scores, subjs)\n",
    "\n",
    "\n",
    "def test_metric(ma: MetricArray, subjs: list, metric, params=None) -> tuple:\n",
    "    if params is None:\n",
    "        return test_metric_single(m, subjs, metric, {}, True)\n",
    "    else:\n",
    "        best_score = test_metric_single(m, subjs, metric, params[0], False)\n",
    "        best_param = params[0]\n",
    "        for param in params:\n",
    "            score = test_metric_single(m, subjs, metric, param, False)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_param = param\n",
    "        print('%40s%s' % ('', best_param))\n",
    "        return test_metric_single(m, subjs, metric, best_param, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 files\n",
      "Found 23 subj scores\n",
      "Length after cropping: 1\n",
      "Length after excluding absent: 1\n",
      "Path exists\n",
      "Path masks/happy_dog_mask.mp4 doesnt exists\n"
     ]
    }
   ],
   "source": [
    "seq_name = 'happy_dog'\n",
    "file = f'np_arrays/{seq_name}_div8.npy'\n",
    "folder = f'ugc/{seq_name}_x265/'\n",
    "mask_path = f'masks/{seq_name}_mask.mp4'\n",
    "videos = sorted(os.listdir(folder))\n",
    "\n",
    "bscores = []\n",
    "subjs = get_subj_scores(videos)\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            bscores.append(np.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f'Found {len(bscores)} files')\n",
    "print(f'Found {len(subjs)} subj scores')\n",
    "\n",
    "videos = videos[0:len(bscores)]\n",
    "subjs = subjs[0:len(bscores)]\n",
    "assert len(videos) == len(bscores) == len(subjs)\n",
    "\n",
    "print('Length after cropping:', len(bscores))\n",
    "\n",
    "deleted = 0\n",
    "for i in range(len(subjs)):\n",
    "    if subjs[i - deleted] is None:\n",
    "        subjs.pop(i - deleted)\n",
    "        videos.pop(i - deleted)\n",
    "        bscores.pop(i - deleted)\n",
    "        deleted += 1\n",
    "\n",
    "print('Length after excluding absent:', len(bscores))\n",
    "\n",
    "m = MetricArray(folder + videos[0], mask_path, 8, 8)\n",
    "m.resize_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metric_multip(m: MetricArray) -> float:\n",
    "    new_mask = m.mask.copy()\n",
    "    res = 0\n",
    "    for mask, metric in zip(new_mask, m.scores):\n",
    "        res += (mask * metric).mean()\n",
    "    res /= m.length\n",
    "    return res\n",
    "\n",
    "def calc_metric_weighted(m: MetricArray) -> float:\n",
    "    new_mask = m.mask.copy()\n",
    "    res = 0\n",
    "    for mask, metric in zip(new_mask, m.scores):\n",
    "        res += (mask * metric).sum() / mask.sum()\n",
    "    res /= m.length\n",
    "    return res\n",
    "\n",
    "def calc_metric_norm(m: MetricArray) -> float:\n",
    "    new_mask = m.mask.copy()\n",
    "    for i in range(m.length):\n",
    "        frame = new_mask[i]\n",
    "        frame -= frame.mean()\n",
    "        frame /= frame.std()\n",
    "        frame += 1\n",
    "        new_mask[i] = frame\n",
    "        # print(frame.mean(), frame.mean(), frame.std())\n",
    "    res = 0\n",
    "    for mask, metric in zip(new_mask, m.scores):\n",
    "        res += (mask * metric).sum() / mask.sum()\n",
    "    res /= m.length\n",
    "    return res\n",
    "\n",
    "def calc_metric_bg_25(m: MetricArray) -> float:\n",
    "    return calc_metric_bg(m, 0.75, 0.25)\n",
    "\n",
    "def calc_metric_bg_minus_93_2(m: MetricArray) -> float:\n",
    "    return calc_metric_bg(m, 0.93, -0.02)\n",
    "\n",
    "def calc_metric_bg_minus_95_5(m: MetricArray) -> float:\n",
    "    return calc_metric_bg(m, 0.95, -0.05)\n",
    "\n",
    "def calc_metric_bg(m: MetricArray, contrast, bias) -> float:\n",
    "    new_mask = m.mask.copy()\n",
    "    new_mask = new_mask * contrast + bias\n",
    "    res = 0\n",
    "    for mask, metric in zip(new_mask, m.scores):\n",
    "        res += (mask * metric).sum() / mask.sum()\n",
    "    res /= m.length\n",
    "    return res\n",
    "\n",
    "def calc_metric_sum(m):\n",
    "    return m.scores.mean()\n",
    "\n",
    "# def calc_metrive_bg_adaptive_bf(m: MetricArray) -> float:    \n",
    "#     best_score, best_contrast, best_bias = 0, 0, 0\n",
    "#     for contrast in contrast_vals:\n",
    "#         for bias in bias_vals:\n",
    "#             score = calc_metric_bg_25(m, contrast, bias)\n",
    "#             if best_score < score:\n",
    "#                 best_score = score\n",
    "#                 best_contrast = contrast\n",
    "#                 best_bias = bias\n",
    "#     print(\">\", best_contrast, best_bias)\n",
    "#     return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(m.mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             calc_metric_sum: nan                                     \n",
      "                                          calc_metric_multip: nan                                     \n",
      "                                        calc_metric_weighted: nan                                     \n",
      "                                           calc_metric_bg_25: nan                                     \n",
      "                                            calc_metric_norm: nan                                     \n",
      "None 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexkkir/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:178: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alexkkir/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2634: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/alexkkir/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2487: RuntimeWarning: invalid value encountered in subtract\n",
      "  X -= avg[:, None]\n",
      "/home/alexkkir/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/alexkkir/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/tmp/ipykernel_3181177/3079760512.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  res += (mask * metric).sum() / mask.sum()\n",
      "/tmp/ipykernel_3181177/3079760512.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  frame /= frame.std()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Value after * must be an iterable, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3181177/2353195546.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best: {best_m}  {round(best_sc, 4)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mbest_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Value after * must be an iterable, not NoneType"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_metrics = [\n",
    "    (calc_metric_sum,),\n",
    "    (calc_metric_multip,),\n",
    "    (calc_metric_weighted,),\n",
    "    (calc_metric_bg_25,),\n",
    "    # (calc_metric_bg_minus_93_2,),\n",
    "    # (calc_metric_bg_minus_95_5,),\n",
    "    (calc_metric_norm,),\n",
    "    # (calc_metric_bg, [{'contrast': 0.93, 'bias': -0.02}]),\n",
    "    # (calc_metric_bg, [{'contrast': q[0], 'bias': q[1]} for q in zip(np.linspace(0.9, 1, 100), np.linspace(-0.1, 0.1, 100))])\n",
    "]\n",
    "\n",
    "best_m = None\n",
    "best_sc = 0\n",
    "best_pair = None\n",
    "for pair in my_metrics:\n",
    "    metric = pair[0]\n",
    "    param = None if len(pair) < 2 else pair[1]\n",
    "    score, scores = test_metric(m, subjs, metric, param)\n",
    "    if score > best_sc:\n",
    "        best_sc = score\n",
    "        best_m = metric.__name__\n",
    "        best_pair = pair\n",
    "    print(f'%60s: %-40s' % (pair[0].__name__, score))\n",
    "\n",
    "print(best_m, best_sc)\n",
    "plt.title(f'Best: {best_m}  {round(best_sc, 4)}')\n",
    "plt.scatter(subjs, test_metric(m, subjs, *best_pair)[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_metrics = [\n",
    "    (calc_metric_bg, [{'contrast': q[0], 'bias': q[1]} for q in zip(np.linspace(0.9, 1, 100), np.linspace(-0.1, 0.1, 100))])\n",
    "]\n",
    "\n",
    "best_m = None\n",
    "best_sc = 0\n",
    "best_pair = None\n",
    "for pair in my_metrics:\n",
    "    metric = pair[0]\n",
    "    param = None if len(pair) < 2 else pair[1]\n",
    "    score, scores = test_metric(m, subjs, metric, param)\n",
    "    if score > best_sc:\n",
    "        best_sc = score\n",
    "        best_m = metric.__name__\n",
    "        best_pair = pair\n",
    "    print(f'%60s: %-40s' % (pair[0].__name__, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product as dot\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "def f(x, y):\n",
    "    return calc_metric_bg(m, x, y)\n",
    "\n",
    "x = list(np.linspace(0.5, 1.5, 20))\n",
    "y = list(np.linspace(-1, 1, 20))\n",
    "\n",
    "coords = np.array(list(dot(x, y)))\n",
    "z = [f(*c) for c in coords]\n",
    "z = [z if 0 <= z <= 1 else 0 for z in z]\n",
    "coords = coords.T\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(coords[0], coords[1], z,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_title('surface');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for angle in range(0, 360):\n",
    "    ax.view_init(30, angle)\n",
    "    plt.draw()\n",
    "    plt.pause(.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

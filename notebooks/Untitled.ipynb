{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8957fca-9b9e-47cf-8242-897ad94c7147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 21:57:05.642831: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alexkkir/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-12 21:57:05.642900: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Kuti\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from math import ceil\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import random\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['animation.ffmpeg_path_vid_vid_vid_vid'] = r'C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe'\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from koniq_api.lib import MyModel\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df372012-bcfd-46a4-910f-fd8bd8427b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_csv = 'subjective_scores.csv'\n",
    "\n",
    "def parse(name: str) -> dict[str]:\n",
    "    out = dict()\n",
    "    name = name.split('.')[0]\n",
    "    name = name.split('enc_res_')[1]\n",
    "\n",
    "    str1 = '_mv_offline_2k_v1_'\n",
    "    str2 = '_mv_offline_2k_'\n",
    "\n",
    "    if name.find(str1) >= 0:\n",
    "        method = 'mv_offline_2k_v1'\n",
    "        name = name.split(str1)\n",
    "    else:\n",
    "        method = 'mv_offline_2k'\n",
    "        name = name.split(str2)\n",
    "\n",
    "    out['method'] = method\n",
    "    out['codec'] = name[0]\n",
    "\n",
    "    name = name[1]\n",
    "    name = name.split('_')\n",
    "    out['crf'] = int(name[-1])\n",
    "\n",
    "    name = '_'.join(name[0:-1])\n",
    "    out['name'] = name\n",
    "    return out\n",
    "\n",
    "def get_1_score(df: pd.DataFrame, name, codec, crf, method):\n",
    "    x = df[(df['comparison'] == 'ugc') & (df['sequence'] == name) & (df['crf'] == int(crf)) & (df['codec'] == codec) & (\n",
    "            df['preset'] == method)]\n",
    "    x = x['subjective']\n",
    "\n",
    "    if len(x) == 1:\n",
    "        x = float(x)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_subj_scores(videos):\n",
    "    subj = pd.read_csv(subjective_csv, sep=';')\n",
    "    return [get_1_score(subj, **parse(name)) for name in videos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b378d515-2248-41bb-b082-358335bf7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'hair_7.npy'\n",
    "folder = 'blue_hair_x265/'\n",
    "videos = sorted(os.listdir(folder))\n",
    "\n",
    "bscores = []\n",
    "subjs = get_subj_scores(videos)\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            bscores.append(np.load(f))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "videos = videos[0:len(bscores)]\n",
    "subjs = subjs[0:len(bscores)]\n",
    "assert len(videos) == len(bscores) == len(subjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f9e500-b7c6-46a2-8ee6-36f3c26df077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268952\n"
     ]
    }
   ],
   "source": [
    "print(sys.getsizeof(bscores * bscores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a4886f-5179-4ff6-9642-4ba9cf9c2311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enc_res_kingsoft_v1_mv_offline_2k_v1_blue_hair_33.mp4', 'enc_res_kingsoft_v1_mv_offline_2k_v1_blue_hair_38.mp4', 'enc_res_kingsoft_v1_mv_offline_2k_v1_blue_hair_43.mp4', 'enc_res_kingsoft_v2_mv_offline_2k_blue_hair_33.mp4', 'enc_res_kingsoft_v2_mv_offline_2k_blue_hair_39.mp4', 'enc_res_kingsoft_v2_mv_offline_2k_blue_hair_45.mp4', 'enc_res_kingsoft_v3_mv_offline_2k_blue_hair_28.mp4']\n",
      "7\n",
      "[5.673068297172945, 5.66340286203501, 5.243526334400184, 6.346977572482853, 6.177970683278712, 5.417861161606206, None]\n"
     ]
    }
   ],
   "source": [
    "print(videos)\n",
    "print(len(bscores))\n",
    "print(subjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c76191-24b6-470a-b28c-a9a2cc821d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enc_res_kingsoft_v1_mv_offline_2k_v1_blue_hair_33.mp4', 'enc_res_kingsoft_v1_mv_offline_2k_v1_blue_hair_38.mp4', 'enc_res_kingsoft_v1_mv_offline_2k_v1_blue_hair_43.mp4', 'enc_res_kingsoft_v2_mv_offline_2k_blue_hair_33.mp4', 'enc_res_kingsoft_v2_mv_offline_2k_blue_hair_39.mp4', 'enc_res_kingsoft_v2_mv_offline_2k_blue_hair_45.mp4']\n",
      "6\n",
      "[5.673068297172945, 5.66340286203501, 5.243526334400184, 6.346977572482853, 6.177970683278712, 5.417861161606206]\n"
     ]
    }
   ],
   "source": [
    "deleted = 0\n",
    "for i in range(len(subjs)):\n",
    "    if subjs[i - deleted] is None:\n",
    "        subjs.pop(i - deleted)\n",
    "        videos.pop(i - deleted)\n",
    "        bscores.pop(i - deleted)\n",
    "        deleted += 1\n",
    "\n",
    "print(videos)\n",
    "print(len(bscores))\n",
    "print(subjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b874a1-e491-4a70-ba13-123b76df1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 2\n",
    "\n",
    "class MetricArray:\n",
    "    def __init__(self, vid_path, mask_path, n_height, n_width):\n",
    "        self.vid = None if vid_path is None else VideoReader(vid_path)\n",
    "        self.n_height = n_height\n",
    "        self.n_width = n_width\n",
    "        self.block_height = self.vid.height // n_height\n",
    "        self.block_width = self.vid.width // n_width\n",
    "        self.scores = np.zeros((self.vid.length, self.n_height, self.n_width))\n",
    "        self.mask_raw = None if mask_path is None else VideoReader(mask_path)\n",
    "        self.metric = MODEL\n",
    "        self.mask = np.zeros_like(self.scores)\n",
    "        self.length = self.vid.length\n",
    "\n",
    "    def get_subframe(self, frame, i, j) -> np.array:\n",
    "        return frame[\n",
    "               i * self.block_height: min(self.vid.height, (i + 1) * self.block_height),\n",
    "               j * self.block_width: min(self.vid.width, (j + 1) * self.block_width)\n",
    "               ]\n",
    "\n",
    "    def split_video(self):\n",
    "        \"\"\"\n",
    "        devide video on n * m subvideos and save each of them in ./tmp/ folder\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        TMP_DIR = './tmp/'\n",
    "        if not os.path.exists(TMP_DIR): \n",
    "            os.mkdir(TMP_DIR)\n",
    "        for f in os.listdir(TMP_DIR):\n",
    "            os.remove(TMP_DIR + f)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "        for i in range(self.n_height):\n",
    "            for j in range(self.n_width):\n",
    "                out = cv2.VideoWriter(f'{TMP_DIR}{i}_{j}.mp4', fourcc, vid.fps, (self.block_width, self.block_height))\n",
    "                for frame in vid:\n",
    "                    subframe = self.get_subframe(frame, i, j)\n",
    "                    out.write(subframe)\n",
    "                out.release()\n",
    "                vid.refresh()\n",
    "                \n",
    "    \n",
    "    def calc_raw_metric(self):\n",
    "        for frame_idx, frame in tqdm(enumerate(self.vid), total=self.length):\n",
    "            for i in range(self.n_height):\n",
    "                for j in range(self.n_width):\n",
    "                    subframe = self.get_subframe(frame, i, j)\n",
    "                    score = self.metric(subframe)\n",
    "                    self.scores[frame_idx][i][j] = score\n",
    "    \n",
    "    def resize_mask(self):\n",
    "        self.mask_raw.refresh()\n",
    "        for fi, frame in enumerate(self.mask_raw):\n",
    "            for i in range(self.mask.shape[1]):\n",
    "                for j in range(self.mask.shape[2]):\n",
    "                    self.mask[fi][i][j] = frame[ \n",
    "                        i * self.block_height : (i + 1) * (self.block_height ), \n",
    "                        j * self.block_width: (j + 1) * (self.block_width)].mean() / 255     \n",
    "        self.mask_raw.refresh()\n",
    "\n",
    "\n",
    "    def apply_mask(self):\n",
    "        return self.scores * self.mask\n",
    "    \n",
    "    def calc_metric(self):\n",
    "        return self.apply_mask().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81ee8795-71d1-4117-be10-76f45822b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metric_dummy_all_together(m: MetricArray) -> float:\n",
    "    new_mask = m.mask.copy()\n",
    "    res = 0\n",
    "    for mask, metric in zip(new_mask, m.scores):\n",
    "        res += (mask * metric).mean()\n",
    "    res /= m.length\n",
    "    return res\n",
    "\n",
    "def calc_metric_dummy_by_frame(m: MetricArray) -> float:\n",
    "    new_mask = m.mask.copy()\n",
    "    res = 0\n",
    "    for mask, metric in zip(new_mask, m.scores):\n",
    "        res += (mask * metric).sum() / mask.sum()\n",
    "    res /= m.length\n",
    "    return res\n",
    "\n",
    "def calc_metric_norm(m: MetricArray) -> float:\n",
    "    new_mask = m.mask.copy()\n",
    "    for i in range(m.length):\n",
    "        frame = new_mask[i]\n",
    "        frame -= frame.mean()\n",
    "        frame /= frame.std()\n",
    "        frame += 1\n",
    "        new_mask[i] = frame\n",
    "        # print(frame.mean(), frame.mean(), frame.std())\n",
    "    res = 0\n",
    "    for mask, metric in zip(new_mask, m.scores):\n",
    "        res += (mask * metric).sum() / mask.sum()\n",
    "    res /= m.length\n",
    "    return res\n",
    "\n",
    "def calc_metric_sum(m):\n",
    "    return m.scores.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d441c3-4965-4aeb-a711-c35af4cc045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoReader:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.cap = cv2.VideoCapture(path)\n",
    "        self.height = int(self.cap.get(4))\n",
    "        self.width = int(self.cap.get(3))\n",
    "        self.it = iter(self)\n",
    "        self.length = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    def __iter__(self):\n",
    "        while self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            yield frame\n",
    "\n",
    "    def __call__(self):\n",
    "        return next(self.it)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.cap.release()\n",
    "\n",
    "    def refresh(self):\n",
    "        self.cap = cv2.VideoCapture(self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a9d563e-e132-4bf7-8eb0-eb4eeb78b776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model InceptionResNetV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 21:57:38.339775: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-04-12 21:57:38.339817: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (alexkkir-Extensa-215-51G): /proc/driver/nvidia/version does not exist\n",
      "2022-04-12 21:57:38.340585: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "MODEL = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00530e0f-6793-432f-b2eb-d3c8c98fd1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pcc(x, y):\n",
    "    return np.corrcoef(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352992c8-0058-47dc-b71f-6bde90059847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63223.899787813425, 65720.45207762718, 62683.14124214649, 56498.16049385071, 63344.35722601414, 62464.953249424696]\n",
      "[5.673068297172945, 5.66340286203501, 5.243526334400184, 6.346977572482853, 6.177970683278712, 5.417861161606206]\n",
      "[[ 1.         -0.54983594]\n",
      " [-0.54983594  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "m = MetricArray(folder + videos[0], 'hair_mask.mp4', 4, 4)\n",
    "m.resize_mask()\n",
    "for video, bscore in zip(videos, bscores):\n",
    "    m.scores = bscore\n",
    "    score = calc_metric_sum(m)\n",
    "    scores.append(score)\n",
    "    \n",
    "print(scores)\n",
    "print(subjs)\n",
    "print(calc_pcc(scores, subjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56212d88-5d22-457a-a2c0-f8900ba34828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38539724256919017, 0.4554052083257252, 0.40356824182723344, 0.33718243308630774, 0.45256664521129236, 0.43741904134237386]\n",
      "[5.673068297172945, 5.66340286203501, 5.243526334400184, 6.346977572482853, 6.177970683278712, 5.417861161606206]\n",
      "[[ 1.         -0.33686407]\n",
      " [-0.33686407  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "m = MetricArray(folder + videos[0], 'hair_mask.mp4', 4, 4)\n",
    "m.resize_mask()\n",
    "for video, bscore in zip(videos, bscores):\n",
    "    m.scores = bscore\n",
    "    score = calc_metric_dummy_all_together(m)\n",
    "    scores.append(score)\n",
    "    \n",
    "print(scores)\n",
    "print(subjs)\n",
    "print(calc_pcc(scores, subjs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
